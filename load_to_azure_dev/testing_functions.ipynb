{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetRetrieval2(year, colour):\n",
    "    '''Finds API endpoint of a dataset given year and colour'''\n",
    "    base_url = \"https://data.cityofnewyork.us/resource/\"\n",
    "\n",
    "    # The discovery API endpoint for datasets\n",
    "    discovery_endpoint = \"https://api.us.socrata.com/api/catalog/v1\"\n",
    "\n",
    "    # Parameters for querying the dataset\n",
    "    params = {\n",
    "        'domains': 'data.cityofnewyork.us',\n",
    "        'search_context': 'data.cityofnewyork.us',\n",
    "        'q': f'{colour} taxi {year}'\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the discovery endpoint with the parameters\n",
    "    response = requests.get(discovery_endpoint, params=params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        datasets = response.json()\n",
    "        \n",
    "        # Extract dataset identifiers and construct API endpoints\n",
    "        for dataset in datasets['results']:\n",
    "            resource = dataset['resource']\n",
    "            dataset_id = resource['id']\n",
    "            dataset_name = resource['name']\n",
    "            api_endpoint = f\"{base_url}{dataset_id}.csv\"\n",
    "            \n",
    "            if set(year).issubset(set(dataset_name)) and set(colour.lower()).issubset(set(dataset_name.lower())):\n",
    "                print(dataset_name)\n",
    "            return api_endpoint\n",
    "    else:\n",
    "        print(f\"Failed to retrieve datasets, status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading data into azure storage account\n",
    "\n",
    "def load_data_to_azure(year:int, data_type:str, data:dict):\n",
    "    '''A function to load data from a python object into Triathlon Azure \n",
    "    Storage Account'''\n",
    "    %pip install azure-storage-blob\n",
    "    from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "    container_name = f\"{year}\"\n",
    "    blob_name = f\"{year}_{data_type}_data\"\n",
    "    storage_connection_string = \"DefaultEndpointsProtocol=https;AccountName=triathlonnyc;AccountKey=wfxBgbmGNXsXavVUF48Zn7sBj5ZNgT60MTArVyDKwn0CdqVebvaYyMWDzKfddso2yX0iiyr2fcK4+AStTsLANQ==;EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic for loading data for all years for yellow taxi data \n",
    "\n",
    "\n",
    "for y in range(2009,2019,1):\n",
    "    # call function to get API end point\n",
    "\n",
    "    # call function to load data into python object using API\n",
    "    \n",
    "    # change to csv file\n",
    "\n",
    "    # load data to azure\n",
    "    load_data_to_azure(y, 'yellow_taxi', data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
